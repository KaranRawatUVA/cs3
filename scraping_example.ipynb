{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIk/QHvxpoXlgYcvr/HRPM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to Scrape for Inauguration Speeches"
      ],
      "metadata": {
        "id": "k93XinPBw0wL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up the File"
      ],
      "metadata": {
        "id": "gZlB203Zw805"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SZLm0V7-u8mC"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "# the requests package lets you get the html of a website's url you provide\n",
        "from bs4 import BeautifulSoup as soup\n",
        "# this package will help go through the html of the website\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "header = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0\"\n",
        "}\n",
        "\n",
        "# this is what the website you scrape will see when you request it"
      ],
      "metadata": {
        "id": "VTKsM-NxwpU2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping for the Links"
      ],
      "metadata": {
        "id": "eIgZcmlSxEnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.presidency.ucsb.edu/documents/app-categories/spoken-addresses-and-remarks/presidential/inaugural-addresses?items_per_page=60\"\n",
        "# if you look at the website, it is just links to the speeches\n",
        "# we want to get each speech's link\n",
        "raw = requests.get(url, headers=header)\n",
        "# this gets the raw html data from the url\n"
      ],
      "metadata": {
        "id": "DDDxKx_bxGUd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bsObj = soup(raw.content, \"html.parser\")  # Parse the html\n",
        "links = bsObj.find_all(\"div\", class_=\"field-title\")\n",
        "# this gets all the html with the links in the website by\n",
        "# getting all the div's with a class of \"field-title\"\n",
        "names = bsObj.find_all(\"div\", class_=\"col-sm-4 margin-top\")\n",
        "# this gets all the html with the names of the president's, by\n",
        "# getting all the divs with the stated class above"
      ],
      "metadata": {
        "id": "1HfbGaRBxKHV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "president_names = [name.p.a.text for name in names]\n",
        "# this gets all of the names from the HTML from the names we picked out\n",
        "speech_links = [title.find(\"a\")[\"href\"] for title in links]\n",
        "# this gets all of the links' end (after the .edu) by looking for the href in the html\n"
      ],
      "metadata": {
        "id": "40l9JicKyrsU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There is a second page with more speeches\n",
        "# so we add that now using the same method\n",
        "\n",
        "# add second list\n",
        "url = \"https://www.presidency.ucsb.edu/documents/app-categories/spoken-addresses-and-remarks/presidential/inaugural-addresses?items_per_page=60&page=1\"\n",
        "raw = requests.get(url, headers=header)\n",
        "\n"
      ],
      "metadata": {
        "id": "wqBAk0050gsY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bsObj = soup(raw.content, \"html.parser\")\n",
        "links = bsObj.find_all(\"div\", class_=\"field-title\")\n",
        "names = bsObj.find_all(\"div\", class_=\"col-sm-4 margin-top\")\n"
      ],
      "metadata": {
        "id": "5FlmNBg30rBz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# these just add to the arrays using extend\n",
        "\n",
        "president_names.extend([name.p.a.text for name in names])\n",
        "\n",
        "speech_links.extend([title.find(\"a\")[\"href\"] for title in links])\n"
      ],
      "metadata": {
        "id": "t2XQaizN0sGS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps"
      ],
      "metadata": {
        "id": "tQOHnDzn1G6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have all the links, you must find out a way to \"request\" the url of each speech and then get the speech, so you can preform a sentiment analysis on it.\n",
        "\n",
        "**Hint:** When parsing each url, you have to get the speech text using this class:\n",
        "```\n",
        "speech = bsObj.find_all(class_=\"field-docs-content\")\n",
        "```\n",
        "\n",
        "Good Luck!\n"
      ],
      "metadata": {
        "id": "YrBqURkG1JII"
      }
    }
  ]
}